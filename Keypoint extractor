import cv2 
import numpy as np
import mediapipe as mp
import pandas as pd
from azure.storage.blob import BlobServiceClient

# Azure Blob Storage Access Settings & Connection
image_container = 'img-beg-train'
connect_str = ('')

try:
    blob_service_client = BlobServiceClient.from_connection_string(connect_str)
    image_container_client = blob_service_client.get_container_client(image_container)
    print("Connected to Azure Blob Storage container:", image_container)
except Exception as e:
    print("Error connecting to Azure Blob Storage:", e)
    exit()

# Retrieve and sort all image files from the container
blob_list = [blob.name for blob in image_container_client.list_blobs() 
             if blob.name.lower().endswith('.jpg')]
print(f"Found {len(blob_list)} JPEG blobs in container '{image_container}'.")
blob_list.sort()

# Init Mediapipe Hand Detection with one hand only.
mp_hands = mp.solutions.hands

def create_empty_landmark_dict():
    """Create an empty landmark dictionary with all values set to NaN, plus a hand label."""
    d = {}
    for i in range(21):
        d[f'lm_{i}_x'] = np.nan
        d[f'lm_{i}_y'] = np.nan
        d[f'lm_{i}_z'] = np.nan
    d['hand'] = np.nan
    return d

def process_hand_landmarks(hand_landmarks, hand_label):
    """
    Extract hand landmarks without any rotation or mirroring.
    Also add a 'hand' field to indicate if it is right or left.
    """
    hand_dict = {}
    for i, lm in enumerate(hand_landmarks.landmark):
        hand_dict[f'lm_{i}_x'] = lm.x
        hand_dict[f'lm_{i}_y'] = lm.y
        hand_dict[f'lm_{i}_z'] = lm.z
    hand_dict['hand'] = hand_label  # 'right' or 'left'
    return hand_dict

def has_redundant_rows(df, threshold=5):
    """Check if a sequence has at least threshold identical rows."""
    return (df.duplicated().sum() >= threshold)

# Lists to store sequences of hand landmark data (each sequence is 20 frames)
all_sequences = []
current_seq = []

with mp_hands.Hands(static_image_mode=True,
                    max_num_hands=1,
                    min_detection_confidence=0.5) as hands_detector:
    
    for idx, blob_name in enumerate(blob_list):
        try:
            # Download and read the image
            blob_client = image_container_client.get_blob_client(blob_name)
            image_bytes = blob_client.download_blob().readall()
            np_arr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            
            # Initialize row with NaNs
            row = create_empty_landmark_dict()
            
            if image is None:
                print(f"Warning: Unable to decode image {blob_name}. Using NaN for landmarks.")
            else:
                # Convert image for MediaPipe processing
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                results = hands_detector.process(image_rgb)
                
                if results.multi_hand_landmarks and results.multi_handedness:
                    # Only use the first detected hand.
                    hand_landmarks = results.multi_hand_landmarks[0]
                    hand_label = results.multi_handedness[0].classification[0].label.lower()
                    row = process_hand_landmarks(hand_landmarks, hand_label)
                else:
                    print(f"No hand detected in image {blob_name}.")
            
            current_seq.append(row)
            
        except Exception as e:
            print(f"Error processing {blob_name}: {e}")
            current_seq.append(create_empty_landmark_dict())

        # Every 20 frames, process the sequence batch
        if (idx + 1) % 20 == 0:
            df_seq = pd.DataFrame(current_seq)
            # If no valid landmarks detected in the sequence, mark sequence with NaNs.
            if df_seq.dropna(how='all').empty:
                print("Sequence has no valid landmarks; marking sequence with NaNs.")
                nan_seq = pd.DataFrame([create_empty_landmark_dict() for _ in range(len(current_seq))])
                all_sequences.append(nan_seq)
            else:
                df_seq.interpolate(method='linear', inplace=True, limit_direction='both')
                # If sequence has excessive duplicate rows, mark sequence with NaNs.
                if has_redundant_rows(df_seq):
                    print("Sequence has excessive duplicate rows; marking sequence with NaNs.")
                    nan_seq = pd.DataFrame([create_empty_landmark_dict() for _ in range(len(current_seq))])
                    all_sequences.append(nan_seq)
                else:
                    all_sequences.append(df_seq)
                
            current_seq = []

# Combine all sequences and save to CSV file
if all_sequences:
    df_final_hand_data = pd.concat(all_sequences, ignore_index=True)
    df_final_hand_data.to_csv("kps_beg_train.csv", index=False)
    print("Hand landmark CSV saved to 'hand_landmark_data.csv'.")
else:
    print("No valid hand sequences were processed.")
