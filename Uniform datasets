import pandas as pd 
import numpy as np

# Function to process a single CSV file
def process_csv(file_path, output_path):
    df = pd.read_csv(file_path, header=None)

    num_kp = 50  # Number of keypoints to keep
    kp_size = 5  # Each keypoint consists of 5 values

    processed_rows = []
    for _, row in df.iterrows():
        row_values = row.values

        # Split the row into groups of 5 (each group is one keypoint)
        valid_keypoints = []
        for i in range(0, len(row_values), kp_size):
            group = row_values[i:i+kp_size]
            # Ensure the group has exactly 5 elements
            if len(group) < kp_size:
                break
            # If any value in the keypoint is NaN, skip this entire keypoint
            if np.isnan(group).any():
                continue
            valid_keypoints.append(group)
        
        valid_keypoints = np.array(valid_keypoints)
        num_valid = valid_keypoints.shape[0] if valid_keypoints.ndim > 1 else 0

        # If we have at least 50 valid keypoints, take the first 50.
        # Otherwise, fill the missing keypoints with averages (or zeros if none are available)
        if num_valid >= num_kp:
            truncated = valid_keypoints[:num_kp]
        else:
            if num_valid == 0:
                truncated = np.zeros((num_kp, kp_size))
            else:
                avg_values = np.mean(valid_keypoints, axis=0)
                missing_rows = num_kp - num_valid
                fill_values = np.tile(avg_values, (missing_rows, 1))
                truncated = np.vstack((valid_keypoints, fill_values))

        # Normalize each descriptor column independently
        for col in range(kp_size):
            col_data = truncated[:, col]
            mean_val = np.mean(col_data)
            std_val = np.std(col_data)
            # Avoid division by zero
            std_val = std_val if std_val != 0 else 1
            truncated[:, col] = (col_data - mean_val) / std_val

        # Flatten the processed keypoints and add to the list of processed rows
        processed_rows.append(truncated.flatten())

    # Convert the list of processed rows into a DataFrame
    processed_df = pd.DataFrame(processed_rows)

    # Generate column labels for the output CSV
    column_labels = []
    for i in range(1, num_kp + 1):
        column_labels.extend([
            f"kp{i}_x", f"kp{i}_y", f"greyscalevalue{i}",
            f"kpopticalflow{i}_x", f"kpopticalflow{i}_y"
        ])
    processed_df.columns = column_labels

    # Save the processed DataFrame to a CSV file
    processed_df.to_csv(output_path, index=False)

# List of input and output files
input_files = {
    "holdout_advanced_features.csv": "processed_holdout_advanced_features.csv",
    "holdout_beginner_features.csv": "processed_holdout_beginner_features.csv",
    "train_advanced_features.csv": "processed_train_advanced_features.csv",
    "train_beginner_features.csv": "processed_train_beginner_features.csv"
}

# Process each file separately
for input_file, output_file in input_files.items():
    process_csv(input_file, output_file)
    print(f"Processed {input_file} -> {output_file}")
